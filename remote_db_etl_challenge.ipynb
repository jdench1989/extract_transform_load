{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "Identify the top 5 members in terms of booking frequency.\n",
    "\n",
    "To identify the top 5 members in terms of booking frequency, focus on the bookings table. This table contains all the information you need to determine how frequently each member has made bookings. Remember, aggregation and sorting will be key techniques in this challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract \n",
    "First I'l load the required dependencies and establish the connection parameters for the remote transactional database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "# The connection details (user, password, host) below are placeholders.\n",
    "# Your coach will provide you with the actual connection details for your exercises.\n",
    "\n",
    "conn_params = {\n",
    "    'host': 'etl-relational-database.cfmnnswnfhpn.eu-west-2.rds.amazonaws.com',\n",
    "    'dbname': 'postgres',\n",
    "    'user': 'readonly_user',\n",
    "    'password': 'you-can-only-read'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, define the function that will be used to fetch data from the remote DB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(query):\n",
    "    with psycopg2.connect(**conn_params) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            data = cur.fetchall()\n",
    "            colnames = [desc[0] for desc in cur.description]\n",
    "    return data, colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then fetch the necessary data and create a pandas dataframe with it. \n",
    "\n",
    "As the member id isn't particularly useful in answering the question on it's own I will join the members and bookings tables to get the first and last names of the top 5 members, rather than just their member id's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>memid</th>\n",
       "      <th>surname</th>\n",
       "      <th>firstname</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GUEST</td>\n",
       "      <td>GUEST</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Rownam</td>\n",
       "      <td>Tim</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>Darren</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Smith</td>\n",
       "      <td>Tracy</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Boothe</td>\n",
       "      <td>Tim</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   memid surname firstname  count\n",
       "0      0   GUEST     GUEST    883\n",
       "1      3  Rownam       Tim    408\n",
       "2      1   Smith    Darren    261\n",
       "3      2   Smith     Tracy    210\n",
       "4      8  Boothe       Tim    188"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract bookings data\n",
    "query = \"SELECT b.memid, m.surname, m.firstname, COUNT(b.memid) as count FROM bookings b JOIN members m ON b.memid = m.memid GROUP BY b.memid, m.surname, m.firstname ORDER BY count DESC LIMIT 5\"\n",
    "bookings_data, colnames = fetch_data(query)\n",
    "bookings_df = pd.DataFrame(bookings_data, columns=colnames)\n",
    "bookings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "My personal preference is to use SQL to directly extract the required data. This minimises the number of steps required to transform the data and streamlines the process slightly. \n",
    "\n",
    "However, this would only really be appropriate if I knew that only one particular transformation of the data is needed. If multiple different transformations were required, or if I wasn't certain that I only needed one specific transformation, it might be better to use a broader SQL query and to manipulate the data as required with Pandas.\n",
    "\n",
    "This way I could just query the remote database once and conduct multiple transformations on the result if needed. I've show below how I would go about doing this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# query = \"SELECT * FROM bookings b JOIN members m USING (memid)\"\n",
    "\n",
    "# bookings_data, colnames = fetch_data(query)\n",
    "# bookings_df = pd.DataFrame(bookings_data, columns=colnames)\n",
    "\n",
    "# # Grouping by memid, surname, and firstname and counting occurrences\n",
    "# grouped_data = bookings_df.groupby(['memid', 'surname', 'firstname']).size().reset_index(name='count')\n",
    "\n",
    "# # Sorting the data by count in descending order and taking the top 5\n",
    "# top_5 = grouped_data.sort_values(by='count', ascending=False).head(5)\n",
    "\n",
    "# top_5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "Once I have th necessary data in a dataframe I then need to insert that data into my local analytical database. \n",
    "\n",
    "In the cell below I set up the connection to my analytical database and then execute to query to create a table which I will populate with my transformed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query_postgresql(conn_string, query):\n",
    "    with psycopg2.connect(conn_string) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "\n",
    "# Define the connection string for your analytical database\n",
    "etl_bites_conn_string = \"dbname='etl_bites' user='jackdench' host='localhost' port='5432'\"\n",
    "\n",
    "# SQL query to create a new table for storing total booking duration per facility\n",
    "create_total_bookings_table = '''\n",
    "CREATE TABLE top_5_members (\n",
    "    MemberId INTEGER NOT NULL,\n",
    "    MemberSurname TEXT,\n",
    "    MemberFirstname TEXT,\n",
    "    BookingsCount INTEGER\n",
    ");\n",
    "'''\n",
    "\n",
    "# Execute the query to create the table\n",
    "execute_query_postgresql(etl_bites_conn_string, create_total_bookings_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I will execute the INSERT query to populate the analytical database with my transformed data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_data(conn_string, table_name, data, columns):\n",
    "    with psycopg2.connect(conn_string) as conn:\n",
    "        with conn.cursor() as cur:\n",
    "            for row in data.itertuples(index=False):\n",
    "                insert_query = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(['%s'] * len(columns))});\"\n",
    "                cur.execute(insert_query, row)\n",
    "            conn.commit()\n",
    "\n",
    "# Insert the transformed data into the analytical database\n",
    "insert_data(etl_bites_conn_string, 'top_5_members', bookings_df, ['MemberId', 'MemberSurname', 'MemberFirstname', 'BookingsCount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have included a screenshot from TablePlus in my submission showing the data successfully loaded there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etl_bites_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
